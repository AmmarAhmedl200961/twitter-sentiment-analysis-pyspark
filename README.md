# Twitter Sentiment Analysis with PySpark

This repository hosts a project focused on analyzing sentiment in Twitter data using the PySpark framework. The project processes a large dataset from Twitter (Sentiment140), utilizing big data technologies to perform sentiment analysis at scale.

## Table of Contents

- [Technologies Used](#technologies-used)
- [Project Overview](#project-overview)
- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)

## Technologies Used

- Python 3
- Apache Spark
- PySpark
- Jupyter Notebook

## Project Overview

This project applies natural language processing techniques to assess sentiments expressed in tweets. Utilizing the power of Apache Spark and PySpark, the analysis scales to handle large volumes of data efficiently, making it ideal for real-world social media datasets.

## Dataset

The Sentiment140 dataset is used in this project, containing 140 million tweets labeled for sentiment. This dataset allows for robust training and testing of the sentiment analysis model.

- **Source**: The dataset can be downloaded from [Sentiment140](https://huggingface.co/datasets/stanfordnlp/sentiment140). 

## Installation

Ensure you have Python and Apache Spark installed on your system. Follow these steps to set up the environment:

1. **Clone the repository**:
    ```bash
    git clone https://github.com/yourusername/twitter-sentiment-analysis-pyspark.git
    ```

2. **Navigate to the project directory**:
    ```bash
    cd twitter-sentiment-analysis-pyspark
    ```

3. **Install Python dependencies**:
   
not necessarily needed, just run in colab, each notebook is self-contained and can be executed independently.

## Usage

To run the notebook, open the Jupyter Notebook in your preferred editor and follow the provided instructions.
